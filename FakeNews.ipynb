{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# load libraries\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Import data\r\n",
    "data = pd.read_csv(r\"C:\\Users\\User\\Desktop\\fakenews_dataset20210819.csv\")\r\n",
    "data.head()"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get info of data\r\n",
    "data.info()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Count the missing value in every column\r\n",
    "data.isnull().sum()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Get percentage count of loanStatus\r\n",
    "data['target'].value_counts(normalize=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The dataset is a imbalance data because most of the data are under label 0. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = data.drop('id', axis=1)\r\n",
    "data = data.drop('news_url',axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Exploration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def boxplot(column):\r\n",
    "    sns.boxplot(x = 'target',\r\n",
    "            y=column,\r\n",
    "            data=data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Save boxplot of all columns to pdf\r\n",
    "with PdfPages('boxplot.pdf') as pdf: \r\n",
    "    for column in data:\r\n",
    "     fig = boxplot(column)\r\n",
    "     pdf.savefig(fig)\r\n",
    "     plt.close()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Remove outliers\r\n",
    "df1 = data[(data[\"avg_sentence_length\"] < 5)]\r\n",
    "df2= df1[(df1[\"arousal\"] < 5.5)]\r\n",
    "df3= df2[(df2[\"dominance\"] < 5.5)]\r\n",
    "df_filtered = df3[(df3[\"polarity\"] > -0.75)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_filtered.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Engineering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_filtered['noun_perc'] = df_filtered['noun_density']/df_filtered['avg_sentence_length']\r\n",
    "df_filtered['verb_perc'] = df_filtered['verb_density']/df_filtered['avg_sentence_length']\r\n",
    "df_filtered['adverb_perc'] = df_filtered['adverb_density']/df_filtered['avg_sentence_length']\r\n",
    "df_filtered['adjective_perc'] = df_filtered['adjective_density']/df_filtered['avg_sentence_length']\r\n",
    "df_filtered['preposition_perc'] = df_filtered['preposition_density']/df_filtered['avg_sentence_length']\r\n",
    "df_filtered['conjunction_perc'] = df_filtered['conjunction_density']/df_filtered['avg_sentence_length']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_filtered.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Normalization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = df_filtered\r\n",
    "# create scaler\r\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\r\n",
    "# fit scaler on data\r\n",
    "scaler.fit(df)\r\n",
    "# apply transform\r\n",
    "normalised = scaler.transform(df)\r\n",
    "\r\n",
    "df_scaled = pd.DataFrame(normalised, columns=df.columns,index=df.index)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df_scaled.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.feature_selection import SelectKBest\r\n",
    "from sklearn.feature_selection import chi2\r\n",
    "\r\n",
    "#concat two dataframes for better visualization \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X=df_scaled.drop('target',axis=1)\r\n",
    "y=df_scaled['target']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#apply SelectKBest class to extract top 10 best features\r\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=10)\r\n",
    "fit = bestfeatures.fit(X,y)\r\n",
    "dfscores = pd.DataFrame(fit.scores_)\r\n",
    "dfcolumns = pd.DataFrame(X.columns)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\r\n",
    "featureScores.columns = ['Featured','Score']  #naming the dataframe columns\r\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X = X.drop([\"conjunction_density\", \"binned_interjection_density\", \"title_words\"], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_columns = X.columns.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modeling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.model_selection import train_test_split \r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "from sklearn import metrics \r\n",
    "from sklearn import tree"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Hyperparameter Tuning\r\n",
    "dt = DecisionTreeClassifier(random_state=42)\r\n",
    "\r\n",
    "params = {\r\n",
    "    'max_depth': [2, 3, 5, 10, 20],\r\n",
    "    'min_samples_leaf': [5, 10, 20, 50, 100],\r\n",
    "    'criterion': [\"gini\", \"entropy\"],\r\n",
    "    'splitter': [\"best\", \"random\"]\r\n",
    "}\r\n",
    "\r\n",
    "# Instantiate the grid search model\r\n",
    "grid_search = GridSearchCV(estimator=dt, \r\n",
    "                           param_grid=params, \r\n",
    "                           cv=4, n_jobs=-1, verbose=1, scoring = \"accuracy\")\r\n",
    "\r\n",
    "grid_search.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_search.best_estimator_\r\n",
    "dt_best = grid_search.best_estimator_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred_dt = dt_best.predict(X_test)\r\n",
    "\r\n",
    "# Model Accuracy, how often is the classifier correct?\r\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_dt))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(25,20))\r\n",
    "_ = tree.plot_tree(dt_best, \r\n",
    "                   feature_names=X_columns,  \r\n",
    "                   filled=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "source": [
    "lr = LogisticRegression(random_state=42)\r\n",
    "\r\n",
    "params_lr = {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\r\n",
    "    'C' : np.logspace(-4, 4, 20),\r\n",
    "    'solver' : ['lbfgs','newton-cg','liblinear','sag','saga'],\r\n",
    "    'class_weight' : ['balanced'],\r\n",
    "    'max_iter' : [100, 500, 1000]\r\n",
    "    }\r\n",
    "    \r\n",
    "# Instantiate the grid search model\r\n",
    "grid_search_lr = GridSearchCV(estimator = lr, \r\n",
    "                                param_grid = params_lr, \r\n",
    "                                cv = 4, \r\n",
    "                                verbose=True, \r\n",
    "                                n_jobs=-1, scoring = \"accuracy\")\r\n",
    "\r\n",
    "grid_search_lr.fit(X_train, y_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "grid_search_lr.best_estimator_\r\n",
    "lr_best = grid_search.best_estimator_"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_pred_lr = lr_best.predict(X_test)\r\n",
    "\r\n",
    "# Model Accuracy, how often is the classifier correct?\r\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_dt))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "8fac594bfae6525c0c41b4041d2d72effa188cc8ead05f81b1fab2bb098927fb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
